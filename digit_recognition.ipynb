{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import notMNIST_gen\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Download Complete\n",
      "Extract Complete\n",
      "Saving Complete\n",
      "Data Dictionaries Built\n",
      "Training set (200000, 64, 64) (200000,)\n",
      "Validation set (10000, 64, 64) (10000,)\n",
      "Test set (10000, 64, 64) (10000,)\n",
      "[b'A' b'B' b'E' b'H' b' ']\n"
     ]
    }
   ],
   "source": [
    "# Load Sythetic Dataset\n",
    "save = notMNIST_gen.gen_composite()\n",
    "train_dataset = save['train_dataset']\n",
    "train_labels = save['train_labels']\n",
    "valid_dataset = save['valid_dataset']\n",
    "valid_labels = save['valid_labels']\n",
    "test_dataset = save['test_dataset']\n",
    "test_labels = save['test_labels']\n",
    "del save  # hint to help gc free up memory\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "labels = train_labels\n",
    "new_labels = labels.view('S1').reshape((labels.size, -1))\n",
    "print(new_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 64, 64, 1) (200000, 5, 11)\n",
      "Validation set (10000, 64, 64, 1) (10000, 5, 11)\n",
      "Test set (10000, 64, 64, 1) (10000, 5, 11)\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "num_digits = 5\n",
    "char_labels = [b'A',b'B',b'C',b'D',b'E',b'F',b'G',b'H',b'I',b'J',b' ']\n",
    "num_labels = len(char_labels)\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = labels.view('S1').reshape((labels.size, -1))\n",
    "  new_labels = np.ndarray(labels.shape, dtype=np.float32)\n",
    "  for i in range(new_labels.shape[0]):\n",
    "    for j in range(new_labels.shape[1]):\n",
    "        if labels[i,j] in char_labels:\n",
    "            new_labels[i,j] = char_labels.index(labels[i,j])\n",
    "  labels = (np.arange(num_labels) == new_labels[:,:,None])\n",
    "  labels = labels.astype(np.float32)\n",
    "  return dataset, labels\n",
    "original_train_labels = train_labels.copy()\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    correct_digits = (np.argmax(predictions, 2) == np.argmax(labels, 2))\n",
    "    correct_addrs = np.all(correct_digits, 1)\n",
    "    return (100.0 * np.sum(correct_addrs) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "  with tf.name_scope('input_variables'):\n",
    "      tf_train_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(batch_size, image_size, image_size, num_channels), \n",
    "          name='train_dataset_in')\n",
    "        \n",
    "      tf_train_labels = tf.placeholder(\n",
    "          tf.float32, shape=(batch_size, num_digits, num_labels), name='train_labels_in')\n",
    "    \n",
    "      tf_prediction_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(batch_size, image_size, image_size, num_channels),\n",
    "          name='prediction_dataset_in')\n",
    "        \n",
    "      tf_keep_prob = tf.constant(0.8, name='keep_probability')\n",
    "\n",
    "  def cnn_var_dict():\n",
    "      var_dict = {}\n",
    "      with tf.name_scope('convolutional_net_variables'):\n",
    "          var_dict['layer_1_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, num_channels, depth], stddev=0.1), \n",
    "                                                  name='cnn_layer_1_weights')\n",
    "          var_dict['layer_1_biases'] = tf.Variable(tf.zeros([depth]), \n",
    "                                                  name='cnn_layer_1__biases')\n",
    "          var_dict['layer_2_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, depth, depth], stddev=0.1), \n",
    "                                                  name='cnn_layer_2_weights')\n",
    "          var_dict['layer_2_biases'] = tf.Variable(tf.constant(1.0, shape=[depth]), \n",
    "                                                  name='cnn_layer_2_biases')\n",
    "          for key in var_dict:\n",
    "            tf.summary.histogram(key + '_summary', var_dict[key])\n",
    "      return var_dict\n",
    "\n",
    "  def variable_dict(digit):\n",
    "      var_dict = {}\n",
    "      with tf.name_scope('Digit_' + digit + '_variables'):\n",
    "          var_dict['layer_1_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [image_size // 4 * image_size // 4 * depth, num_hidden*3], stddev=0.1), \n",
    "                                                   name='layer_1_'+ digit + '_weights')\n",
    "          var_dict['layer_1_biases'] = tf.Variable(tf.constant(1.0, shape=[num_hidden*3]), \n",
    "                                                  name='layer_1_'+ digit + '_biases')\n",
    "          var_dict['layer_2_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [num_hidden*3, num_hidden*2], stddev=0.1), \n",
    "                                                   name='layer_2_'+ digit + '_weights')\n",
    "          var_dict['layer_2_biases'] = tf.Variable(tf.constant(1.0, shape=[num_hidden*2]), \n",
    "                                                  name='layer_2_'+ digit + '_biases')\n",
    "          var_dict['layer_3_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [num_hidden*2, num_hidden], stddev=0.1), \n",
    "                                                   name='layer_3_'+ digit + '_weights')\n",
    "          var_dict['layer_3_biases'] = tf.Variable(tf.constant(1.0, shape=[num_hidden]), \n",
    "                                                  name='layer_3_'+ digit + '_biases')\n",
    "          var_dict['layer_4_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [num_hidden, num_labels], stddev=0.1), name='layer_4_'+ digit + '_weights')\n",
    "          var_dict['layer_4_biases'] = tf.Variable(tf.constant(1.0, shape=[num_labels]), \n",
    "                                                  name='layer_4_'+ digit + '_biases')\n",
    "          for key in var_dict:\n",
    "            tf.summary.histogram(key + '_summary', var_dict[key])\n",
    "      return var_dict\n",
    "\n",
    "  cnn_vars = cnn_var_dict()\n",
    "  deep_vars = {}\n",
    "  for i in range(num_digits):\n",
    "        deep_vars[str(i)] = variable_dict(str(i))\n",
    "                      \n",
    "  # Model.\n",
    "  def cnn_model(data, var_set):\n",
    "    with tf.name_scope('convolutional_net_operations'):\n",
    "        conv_1 = tf.nn.conv2d(data, var_set['layer_1_weights'], [1, 2, 2, 1], padding='SAME', \n",
    "                            name='Convolution_1')\n",
    "        conv_1 = tf.nn.max_pool(conv_1, [1, 4, 4, 1], [1, 1, 1, 1], padding='SAME', name='Max_Pool_1')\n",
    "        conv_1 = tf.nn.relu(conv_1 + var_set['layer_1_biases'], name='CNN_Relu_1')\n",
    "        conv_2 = tf.nn.conv2d(conv_1, var_set['layer_2_weights'], [1, 2, 2, 1], padding='SAME', \n",
    "                            name='Convolution_2')\n",
    "        conv_2 = tf.nn.max_pool(conv_2, [1, 4, 4, 1], [1, 1, 1, 1], padding='SAME', name='Max_Pool_2')\n",
    "        conv_2 = tf.nn.relu(conv_2 + var_set['layer_2_biases'], name='CNN_Relu_2')\n",
    "        shape = conv_2.get_shape().as_list()\n",
    "        reshape = tf.reshape(conv_2, [shape[0], shape[1] * shape[2] * shape[3]], name='Collapse_to_2d')\n",
    "    return reshape\n",
    "\n",
    "  def digit_model(data, digit, keep_prob=1):\n",
    "      with tf.name_scope('Digit_' + digit + '_operations'):\n",
    "        hidden_1 = tf.nn.relu(tf.matmul(data, deep_vars[digit]['layer_1_weights']) + \n",
    "                              deep_vars[digit]['layer_1_biases'], \n",
    "                              name='Digit_' + digit + '_Deep_Relu_1')\n",
    "        drop_1 = tf.nn.dropout(hidden_1, keep_prob)\n",
    "        hidden_2 = tf.nn.relu(tf.matmul(drop_1, deep_vars[digit]['layer_2_weights']) + \n",
    "                              deep_vars[digit]['layer_2_biases'], \n",
    "                              name='Digit_' + digit + '_Deep_Relu_2')\n",
    "        drop_2 = tf.nn.dropout(hidden_2, keep_prob)\n",
    "        hidden_3 = tf.nn.relu(tf.matmul(drop_2, deep_vars[digit]['layer_3_weights']) + \n",
    "                              deep_vars[digit]['layer_3_biases'], \n",
    "                              name='Digit_' + digit + '_Deep_Relu_3')\n",
    "        drop_3 = tf.nn.dropout(hidden_3, keep_prob)\n",
    "        result = tf.matmul(drop_3, deep_vars[digit]['layer_4_weights']) + \\\n",
    "                            deep_vars[digit]['layer_4_biases']\n",
    "      return result\n",
    "\n",
    "  def base_model(data, keep_prob=1):\n",
    "      with tf.name_scope('base_model'):\n",
    "          cnn = cnn_model(data, cnn_vars)\n",
    "          logit_stack = list()\n",
    "          for i in range(num_digits):\n",
    "              logit_stack.append(digit_model(cnn, str(i), keep_prob))\n",
    "      return tf.stack(logit_stack, axis=1)\n",
    "\n",
    "  def train_model(logits, labels):\n",
    "      with tf.name_scope('train_model'):\n",
    "        softmax_stack = list()\n",
    "        pred = list()\n",
    "        for i in range(num_digits):\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits[:,i,:], labels[:,i,:])\n",
    "            softmax_stack.append(tf.reduce_mean(cross_entropy))\n",
    "        loss = tf.reduce_mean(tf.stack(softmax_stack), name='loss_function')\n",
    "      return loss\n",
    "\n",
    "  def make_prediction(logits):\n",
    "      with tf.name_scope('test_model'):\n",
    "        pred = list()\n",
    "        for i in range(num_digits):\n",
    "              pred.append(tf.nn.softmax(logits[:,i,:]))\n",
    "        return tf.stack(pred, axis=1)\n",
    "\n",
    "  def build_loss():\n",
    "    loss_list = list()\n",
    "    loss_list.append(tf.nn.l2_loss(cnn_vars['layer_1_weights']))\n",
    "    loss_list.append(tf.nn.l2_loss(cnn_vars['layer_2_weights']))\n",
    "    return tf.reduce_mean(loss_list)\n",
    "\n",
    "  # Training computation.\n",
    "  with tf.name_scope('training_computation'):\n",
    "      logits = base_model(tf_train_dataset, tf_keep_prob)\n",
    "      loss = train_model(logits, tf_train_labels) + build_loss()\n",
    "\n",
    "  with tf.name_scope('optimizer_computation'):\n",
    "      global_step = tf.Variable(0, name='global_step')  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.001, global_step, 250, 0.99, name='learning_rate')\n",
    "      optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step, \n",
    "                                                                 name='optimizer')\n",
    "  \n",
    "  # Predictions for the validation, and test data.\n",
    "  with tf.name_scope('predictions'):\n",
    "      train_prediction = make_prediction(logits)\n",
    "      batch_predictor = make_prediction(base_model(tf_prediction_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_prediction(dataset, labels):\n",
    "  index = 0\n",
    "  test_accs = []\n",
    "  while index < dataset.shape[0]:\n",
    "    batch_data = dataset[index:index+batch_size, :, :, :]\n",
    "    batch_labels = labels[index:index+batch_size]\n",
    "    feed_dict = {tf_prediction_dataset : batch_data}\n",
    "    batch_pred = batch_predictor.eval(feed_dict=feed_dict)\n",
    "    test_accs.append(accuracy(batch_pred, batch_labels))\n",
    "    index += batch_size\n",
    "  return np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 253.096756; Learing Rate: 0.001000\tMinibatch accuracy: 0.0%\tValidation accuracy: 2.6%\n",
      "Minibatch loss at step 2000: 1.292020; Learing Rate: 0.000923\tMinibatch accuracy: 18.8%\tValidation accuracy: 34.9%\n",
      "Minibatch loss at step 4000: 0.773677; Learing Rate: 0.000851\tMinibatch accuracy: 37.5%\tValidation accuracy: 39.1%\n",
      "Minibatch loss at step 6000: 0.809899; Learing Rate: 0.000786\tMinibatch accuracy: 37.5%\tValidation accuracy: 45.1%\n",
      "Minibatch loss at step 8000: 0.627109; Learing Rate: 0.000725\tMinibatch accuracy: 37.5%\tValidation accuracy: 48.5%\n",
      "Minibatch loss at step 10000: 0.544494; Learing Rate: 0.000669\tMinibatch accuracy: 43.8%\tValidation accuracy: 50.6%\n",
      "Minibatch loss at step 12000: 0.690687; Learing Rate: 0.000617\tMinibatch accuracy: 37.5%\tValidation accuracy: 52.1%\n",
      "Minibatch loss at step 14000: 0.419515; Learing Rate: 0.000570\tMinibatch accuracy: 75.0%\tValidation accuracy: 54.1%\n",
      "Minibatch loss at step 16000: 0.690441; Learing Rate: 0.000526\tMinibatch accuracy: 43.8%\tValidation accuracy: 54.0%\n",
      "Minibatch loss at step 18000: 0.643709; Learing Rate: 0.000485\tMinibatch accuracy: 43.8%\tValidation accuracy: 55.9%\n",
      "Minibatch loss at step 20000: 0.622508; Learing Rate: 0.000448\tMinibatch accuracy: 31.2%\tValidation accuracy: 55.5%\n",
      "Minibatch loss at step 22000: 0.158043; Learing Rate: 0.000413\tMinibatch accuracy: 81.2%\tValidation accuracy: 56.6%\n",
      "Minibatch loss at step 24000: 0.344168; Learing Rate: 0.000381\tMinibatch accuracy: 75.0%\tValidation accuracy: 58.2%\n",
      "Minibatch loss at step 26000: 0.359803; Learing Rate: 0.000352\tMinibatch accuracy: 56.2%\tValidation accuracy: 58.5%\n",
      "Minibatch loss at step 28000: 0.699380; Learing Rate: 0.000324\tMinibatch accuracy: 37.5%\tValidation accuracy: 59.9%\n",
      "Minibatch loss at step 30000: 0.656167; Learing Rate: 0.000299\tMinibatch accuracy: 56.2%\tValidation accuracy: 58.8%\n",
      "Minibatch loss at step 32000: 0.523798; Learing Rate: 0.000276\tMinibatch accuracy: 43.8%\tValidation accuracy: 60.2%\n",
      "Minibatch loss at step 34000: 0.795494; Learing Rate: 0.000255\tMinibatch accuracy: 25.0%\tValidation accuracy: 59.5%\n",
      "Minibatch loss at step 36000: 0.115209; Learing Rate: 0.000235\tMinibatch accuracy: 93.8%\tValidation accuracy: 60.7%\n",
      "Minibatch loss at step 38000: 0.266066; Learing Rate: 0.000217\tMinibatch accuracy: 68.8%\tValidation accuracy: 60.8%\n",
      "Minibatch loss at step 40000: 0.294409; Learing Rate: 0.000200\tMinibatch accuracy: 62.5%\tValidation accuracy: 61.1%\n",
      "Minibatch loss at step 42000: 0.287984; Learing Rate: 0.000185\tMinibatch accuracy: 62.5%\tValidation accuracy: 61.8%\n",
      "Minibatch loss at step 44000: 0.305306; Learing Rate: 0.000171\tMinibatch accuracy: 56.2%\tValidation accuracy: 62.1%\n",
      "Minibatch loss at step 46000: 0.518934; Learing Rate: 0.000157\tMinibatch accuracy: 43.8%\tValidation accuracy: 61.9%\n",
      "Minibatch loss at step 48000: 0.507015; Learing Rate: 0.000145\tMinibatch accuracy: 43.8%\tValidation accuracy: 62.0%\n",
      "Minibatch loss at step 50000: 0.459030; Learing Rate: 0.000134\tMinibatch accuracy: 56.2%\tValidation accuracy: 62.3%\n",
      "Minibatch loss at step 52000: 0.567326; Learing Rate: 0.000124\tMinibatch accuracy: 43.8%\tValidation accuracy: 62.8%\n",
      "Minibatch loss at step 54000: 0.382852; Learing Rate: 0.000114\tMinibatch accuracy: 62.5%\tValidation accuracy: 63.0%\n",
      "Minibatch loss at step 56000: 0.698516; Learing Rate: 0.000105\tMinibatch accuracy: 50.0%\tValidation accuracy: 63.2%\n",
      "Minibatch loss at step 58000: 0.234883; Learing Rate: 0.000097\tMinibatch accuracy: 68.8%\tValidation accuracy: 62.9%\n",
      "Minibatch loss at step 60000: 0.392472; Learing Rate: 0.000090\tMinibatch accuracy: 68.8%\tValidation accuracy: 63.5%\n",
      "Minibatch loss at step 62000: 0.420695; Learing Rate: 0.000083\tMinibatch accuracy: 56.2%\tValidation accuracy: 63.5%\n",
      "Minibatch loss at step 64000: 0.399904; Learing Rate: 0.000076\tMinibatch accuracy: 62.5%\tValidation accuracy: 64.0%\n",
      "Minibatch loss at step 66000: 0.277764; Learing Rate: 0.000070\tMinibatch accuracy: 81.2%\tValidation accuracy: 64.2%\n",
      "Minibatch loss at step 68000: 0.526867; Learing Rate: 0.000065\tMinibatch accuracy: 43.8%\tValidation accuracy: 63.4%\n",
      "Minibatch loss at step 70000: 0.415771; Learing Rate: 0.000060\tMinibatch accuracy: 62.5%\tValidation accuracy: 64.0%\n",
      "Minibatch loss at step 72000: 0.464224; Learing Rate: 0.000055\tMinibatch accuracy: 50.0%\tValidation accuracy: 64.8%\n",
      "Minibatch loss at step 74000: 0.439383; Learing Rate: 0.000051\tMinibatch accuracy: 62.5%\tValidation accuracy: 64.0%\n",
      "Minibatch loss at step 76000: 0.422282; Learing Rate: 0.000047\tMinibatch accuracy: 56.2%\tValidation accuracy: 64.2%\n",
      "Minibatch loss at step 78000: 0.269263; Learing Rate: 0.000043\tMinibatch accuracy: 62.5%\tValidation accuracy: 64.8%\n",
      "Minibatch loss at step 80000: 0.387979; Learing Rate: 0.000040\tMinibatch accuracy: 62.5%\tValidation accuracy: 64.7%\n",
      "Minibatch loss at step 82000: 0.359612; Learing Rate: 0.000037\tMinibatch accuracy: 62.5%\tValidation accuracy: 65.1%\n",
      "Minibatch loss at step 84000: 0.492416; Learing Rate: 0.000034\tMinibatch accuracy: 50.0%\tValidation accuracy: 64.8%\n",
      "Minibatch loss at step 86000: 0.414398; Learing Rate: 0.000032\tMinibatch accuracy: 62.5%\tValidation accuracy: 65.2%\n",
      "Minibatch loss at step 88000: 0.342221; Learing Rate: 0.000029\tMinibatch accuracy: 56.2%\tValidation accuracy: 65.0%\n",
      "Minibatch loss at step 90000: 0.327311; Learing Rate: 0.000027\tMinibatch accuracy: 62.5%\tValidation accuracy: 64.3%\n",
      "Minibatch loss at step 92000: 0.405217; Learing Rate: 0.000025\tMinibatch accuracy: 68.8%\tValidation accuracy: 65.5%\n",
      "Minibatch loss at step 94000: 0.289582; Learing Rate: 0.000023\tMinibatch accuracy: 68.8%\tValidation accuracy: 65.4%\n",
      "Minibatch loss at step 96000: 0.615050; Learing Rate: 0.000021\tMinibatch accuracy: 56.2%\tValidation accuracy: 65.3%\n",
      "Minibatch loss at step 98000: 0.443041; Learing Rate: 0.000019\tMinibatch accuracy: 56.2%\tValidation accuracy: 65.3%\n",
      "Minibatch loss at step 100000: 0.417368; Learing Rate: 0.000018\tMinibatch accuracy: 62.5%\tValidation accuracy: 65.8%\n",
      "Test accuracy: 72.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  writer = tf.summary.FileWriter('logs/nn_logs', graph=graph)\n",
    "  merged = tf.summary.merge_all()\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :, :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, summary, l, predictions, learn = session.run(\n",
    "      [optimizer, merged, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    writer.add_summary(summary, step)\n",
    "    if (step % 2000 == 0):\n",
    "      print('Minibatch loss at step %d: %f; Learing Rate: %f' % (step, l, learn), end='\\t')\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels), end='\\t')\n",
    "      print('Validation accuracy: %.1f%%' % batch_prediction(valid_dataset, valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % batch_prediction(test_dataset, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first approach to the classification portion of this network was to attempt to explicitly isolate each character using OpenCV, then pass the isolated characters to a single digit classifier I have already trained on the notMNIST dataset. Unfortunately, I was unable reach a level of accuracy with this method that I found acceptable.  \n",
    "\n",
    "After further study on the logistics of this approach, I concluded that a deep network should be capable of isolating the characters implicitly. I decided to base this approach on the previously mentioned notMNIST character classifier I had on-hand. This classifier uses a 2d convolution, max_pool and relu sequence to process the input image. This sequence is repeated twice before the data is passed through a pair of matrix multiplications separated by a reul activation.  \n",
    "\n",
    "As this approach achieves a test accuracy of 92.4% on notMNIST, I felt it would likely perform well on the SVHN data, both being difficult computer vision problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final network consists of a single convolutional network passing data to 5 separate fully connected networks, one for each possible digit. The final prediction is created by stacking the results from the individual digit softmax activations.\n",
    "\n",
    "The convolutional network consists of 7 operations. The initial dataset is passed through a convolutional layer with 5x5 patches and stride size of 2. It is then passed through a 4x4 max pooling operation and finally through a relu activation. These three layers are repeated before the data is reshaped into a rank 2 tensor for output to the deep networks. With a batch size of 16, the convolutional network output tensor is 16x4096.\n",
    "\n",
    "Each of the 5 fully connected deep networks have unique weights and biases, sharing the weights between networks resulted in a 15% reduction in validation accuracy. Within each deep network, the dataset is stepped from down from 4096 nodes in stages. Including dropout, these networks consist of 10 operations. Matrix multiplication is followed by relu activation before an 80% keep probability dropout is applied. This is repeated 3 times, stepping 4096 nodes down to 192, then 128 and 64 nodes respectively. The final matrix multiplication results in a 16x11 tensor, which is then passed to a softmax activation to predict the digit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained using batches of 16 images, with the softmax layers is executed as softmax cross entropy with logits. The output from those cross entropy operations are stacked together and passed as a single tensor to a reduce mean operation as the loss function. I chose to use the AdamOptimizer, with an exponential decay learning rate. I found that learning rate of 0.001, decay steps of 200 and decay rate 0.99 resulted in validation accuracy rates I could accept. Training lasted for 100,000 epochs.\n",
    "\n",
    "The synthetic dataset was created by generating a square numpy array and placing letters into the array, using random placement with constraints. The constraints assumed all characters should be below and to the right of previous characters. Once the characters for a sample had been placed, the sample was then resized to the 64x64 image I chose to use. This size was large enough to maintain individual character details, while small enough not to overwhelm the hardware I have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8P8BIySgUU+W0YUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214ca96bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subplt_w = 2\n",
    "subplt_h = 4\n",
    "f, axarr = plt.subplots(subplt_w, subplt_h, sharex=True, sharey=True)\n",
    "count = 0\n",
    "for i in range(subplt_w):\n",
    "    for j in range(subplt_h):\n",
    "        axarr[i, j].imshow(train_dataset[count,:,:,0])\n",
    "        axarr[i, j].set_title(original_train_labels[count].decode('utf-8'))\n",
    "        count += subplt_w + subplt_h\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Download Complete\n",
      "Extract Complete\n",
      "Loading Complete\n",
      "Combine Train and Extra\n",
      "Labels Extracted\n",
      "Dataset Built\n",
      "Training set (203753, 64, 64) (203753, 5)\n",
      "Validation set (32000, 64, 64) (32000, 5)\n",
      "Test set (13068, 64, 64) (13068, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load Sythetic Dataset\n",
    "import prep_svhn\n",
    "save = prep_svhn.get_dataset()\n",
    "train_dataset = save['train_dataset']\n",
    "train_labels = save['train_labels']\n",
    "valid_dataset = save['valid_dataset']\n",
    "valid_labels = save['valid_labels']\n",
    "test_dataset = save['test_dataset']\n",
    "test_labels = save['test_labels']\n",
    "del save  # hint to help gc free up memory\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'3' b'7' b' ' b' ' b' ']\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (203753, 64, 64, 1) (203753, 5, 11)\n",
      "Validation set (32000, 64, 64, 1) (32000, 5, 11)\n",
      "Test set (13068, 64, 64, 1) (13068, 5, 11)\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "num_digits = 5\n",
    "char_labels = [b'0', b'1',b'2',b'3',b'4',b'5',b'6',b'7',b'8',b'9', b' ']\n",
    "num_labels = len(char_labels)\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  new_labels = np.ndarray(labels.shape, dtype=np.float32)\n",
    "  for i in range(new_labels.shape[0]):\n",
    "    for j in range(new_labels.shape[1]):\n",
    "        if labels[i,j] in char_labels:\n",
    "            new_labels[i,j] = char_labels.index(labels[i,j])\n",
    "  labels = (np.arange(num_labels) == new_labels[:,:,None])\n",
    "  labels = labels.astype(np.float32)\n",
    "  return dataset, labels\n",
    "original_train_labels = train_labels.copy()\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    correct_digits = (np.argmax(predictions, 2) == np.argmax(labels, 2))\n",
    "    correct_addrs = np.all(correct_digits, 1)\n",
    "    return (100.0 * np.sum(correct_addrs) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "  with tf.name_scope('input_variables'):\n",
    "      tf_train_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(batch_size, image_size, image_size, num_channels), \n",
    "          name='train_dataset_in')\n",
    "        \n",
    "      tf_train_labels = tf.placeholder(\n",
    "          tf.float32, shape=(batch_size, num_digits, num_labels), name='train_labels_in')\n",
    "    \n",
    "      tf_prediction_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(1, image_size, image_size, num_channels),\n",
    "          name='prediction_dataset_in')\n",
    "        \n",
    "      tf_keep_prob = tf.constant(0.8, name='keep_probability')\n",
    "\n",
    "  def cnn_var_dict():\n",
    "      var_dict = {}\n",
    "      with tf.name_scope('convolutional_net_variables'):\n",
    "          var_dict['layer_1_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, num_channels, depth], stddev=0.1), \n",
    "                                                  name='cnn_layer_1_weights')\n",
    "          var_dict['layer_1_biases'] = tf.Variable(tf.zeros([depth]), \n",
    "                                                  name='cnn_layer_1__biases')\n",
    "          var_dict['layer_2_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [patch_size, patch_size, depth, depth], stddev=0.1), \n",
    "                                                  name='cnn_layer_2_weights')\n",
    "          var_dict['layer_2_biases'] = tf.Variable(tf.constant(1.0, shape=[depth]), \n",
    "                                                  name='cnn_layer_2_biases')\n",
    "          for key in var_dict:\n",
    "            tf.summary.histogram(key + '_summary', var_dict[key])\n",
    "      return var_dict\n",
    "\n",
    "  def variable_dict(digit):\n",
    "      var_dict = {}\n",
    "      with tf.name_scope('Digit_' + digit + '_variables'):\n",
    "          var_dict['layer_1_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [image_size // 4 * image_size // 4 * depth, num_hidden*3], stddev=0.1), \n",
    "                                                   name='layer_1_'+ digit + '_weights')\n",
    "          var_dict['layer_1_biases'] = tf.Variable(tf.constant(1.0, shape=[num_hidden*3]), \n",
    "                                                  name='layer_1_'+ digit + '_biases')\n",
    "          var_dict['layer_2_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [num_hidden*3, num_hidden*2], stddev=0.1), \n",
    "                                                   name='layer_2_'+ digit + '_weights')\n",
    "          var_dict['layer_2_biases'] = tf.Variable(tf.constant(1.0, shape=[num_hidden*2]), \n",
    "                                                  name='layer_2_'+ digit + '_biases')\n",
    "          var_dict['layer_3_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [num_hidden*2, num_hidden], stddev=0.1), \n",
    "                                                   name='layer_3_'+ digit + '_weights')\n",
    "          var_dict['layer_3_biases'] = tf.Variable(tf.constant(1.0, shape=[num_hidden]), \n",
    "                                                  name='layer_3_'+ digit + '_biases')\n",
    "          var_dict['layer_4_weights'] = tf.Variable(tf.truncated_normal(\n",
    "              [num_hidden, num_labels], stddev=0.1), name='layer_4_'+ digit + '_weights')\n",
    "          var_dict['layer_4_biases'] = tf.Variable(tf.constant(1.0, shape=[num_labels]), \n",
    "                                                  name='layer_4_'+ digit + '_biases')\n",
    "          for key in var_dict:\n",
    "            tf.summary.histogram(key + '_summary', var_dict[key])\n",
    "      return var_dict\n",
    "\n",
    "  cnn_vars = cnn_var_dict()\n",
    "  deep_vars = {}\n",
    "  for i in range(num_digits):\n",
    "        deep_vars[str(i)] = variable_dict(str(i))\n",
    "                      \n",
    "  # Model.\n",
    "  def cnn_model(data, var_set):\n",
    "    with tf.name_scope('convolutional_net_operations'):\n",
    "        conv_1 = tf.nn.conv2d(data, var_set['layer_1_weights'], [1, 2, 2, 1], padding='SAME', \n",
    "                            name='Convolution_1')\n",
    "        conv_1 = tf.nn.max_pool(conv_1, [1, 4, 4, 1], [1, 1, 1, 1], padding='SAME', name='Max_Pool_1')\n",
    "        conv_1 = tf.nn.relu(conv_1 + var_set['layer_1_biases'], name='CNN_Relu_1')\n",
    "        conv_2 = tf.nn.conv2d(conv_1, var_set['layer_2_weights'], [1, 2, 2, 1], padding='SAME', \n",
    "                            name='Convolution_2')\n",
    "        conv_2 = tf.nn.max_pool(conv_2, [1, 4, 4, 1], [1, 1, 1, 1], padding='SAME', name='Max_Pool_2')\n",
    "        conv_2 = tf.nn.relu(conv_2 + var_set['layer_2_biases'], name='CNN_Relu_2')\n",
    "        shape = conv_2.get_shape().as_list()\n",
    "        reshape = tf.reshape(conv_2, [shape[0], shape[1] * shape[2] * shape[3]], name='Collapse_to_2d')\n",
    "    return reshape\n",
    "\n",
    "  def digit_model(data, digit, keep_prob=1):\n",
    "      with tf.name_scope('Digit_' + digit + '_operations'):\n",
    "        hidden_1 = tf.nn.relu(tf.matmul(data, deep_vars[digit]['layer_1_weights']) + \n",
    "                              deep_vars[digit]['layer_1_biases'], \n",
    "                              name='Digit_' + digit + '_Deep_Relu_1')\n",
    "        drop_1 = tf.nn.dropout(hidden_1, keep_prob)\n",
    "        hidden_2 = tf.nn.relu(tf.matmul(drop_1, deep_vars[digit]['layer_2_weights']) + \n",
    "                              deep_vars[digit]['layer_2_biases'], \n",
    "                              name='Digit_' + digit + '_Deep_Relu_2')\n",
    "        drop_2 = tf.nn.dropout(hidden_2, keep_prob)\n",
    "        hidden_3 = tf.nn.relu(tf.matmul(drop_2, deep_vars[digit]['layer_3_weights']) + \n",
    "                              deep_vars[digit]['layer_3_biases'], \n",
    "                              name='Digit_' + digit + '_Deep_Relu_3')\n",
    "        drop_3 = tf.nn.dropout(hidden_3, keep_prob)\n",
    "        result = tf.matmul(drop_3, deep_vars[digit]['layer_4_weights']) + \\\n",
    "                            deep_vars[digit]['layer_4_biases']\n",
    "      return result\n",
    "\n",
    "  def base_model(data, keep_prob=1):\n",
    "      with tf.name_scope('base_model'):\n",
    "          cnn = cnn_model(data, cnn_vars)\n",
    "          logit_stack = list()\n",
    "          for i in range(num_digits):\n",
    "              logit_stack.append(digit_model(cnn, str(i), keep_prob))\n",
    "      return tf.stack(logit_stack, axis=1)\n",
    "\n",
    "  def train_model(logits, labels):\n",
    "      with tf.name_scope('train_model'):\n",
    "        softmax_stack = list()\n",
    "        pred = list()\n",
    "        for i in range(num_digits):\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits[:,i,:], labels[:,i,:])\n",
    "            softmax_stack.append(tf.reduce_mean(cross_entropy))\n",
    "        loss = tf.reduce_mean(tf.stack(softmax_stack), name='loss_function')\n",
    "      return loss\n",
    "\n",
    "  def make_prediction(logits):\n",
    "      with tf.name_scope('test_model'):\n",
    "        pred = list()\n",
    "        for i in range(num_digits):\n",
    "              pred.append(tf.nn.softmax(logits[:,i,:]))\n",
    "        return tf.stack(pred, axis=1)\n",
    "\n",
    "  def build_loss():\n",
    "    loss_list = list()\n",
    "    loss_list.append(tf.nn.l2_loss(cnn_vars['layer_1_weights']))\n",
    "    loss_list.append(tf.nn.l2_loss(cnn_vars['layer_2_weights']))\n",
    "    return tf.reduce_mean(loss_list)\n",
    "\n",
    "  # Training computation.\n",
    "  with tf.name_scope('training_computation'):\n",
    "      logits = base_model(tf_train_dataset, tf_keep_prob)\n",
    "      loss = train_model(logits, tf_train_labels) + (build_loss() * 0.001)\n",
    "\n",
    "  with tf.name_scope('optimizer_computation'):\n",
    "      global_step = tf.Variable(0, name='global_step')  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.001, global_step, 250, 0.99, name='learning_rate')\n",
    "      optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step, \n",
    "                                                                 name='optimizer')\n",
    "  \n",
    "  # Predictions for the validation, and test data.\n",
    "  with tf.name_scope('predictions'):\n",
    "      train_prediction = make_prediction(logits)\n",
    "      batch_predictor = make_prediction(base_model(tf_prediction_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_prediction(dataset, labels):\n",
    "  test_accs = []\n",
    "  for i in range(dataset.shape[0]):\n",
    "    batch_data = dataset[i:i+1, :, :, :]\n",
    "    batch_labels = labels[i:i+1]\n",
    "    feed_dict = {tf_prediction_dataset : batch_data}\n",
    "    batch_pred = batch_predictor.eval(feed_dict=feed_dict)\n",
    "    test_accs.append(accuracy(batch_pred, batch_labels))\n",
    "  return np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 19.293100; Learing Rate: 0.001000\tMinibatch accuracy: 0.0%\t"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  writer = tf.summary.FileWriter('logs/nn_logs', graph=graph)\n",
    "  merged = tf.summary.merge_all()\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :, :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, summary, l, predictions, learn = session.run(\n",
    "      [optimizer, merged, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    writer.add_summary(summary, step)\n",
    "    if (step % 2000 == 0):\n",
    "      print('Minibatch loss at step %d: %f; Learing Rate: %f' % (step, l, learn), end='\\t')\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels), end='\\t')\n",
    "      print('Validation accuracy: %.1f%%' % batch_prediction(valid_dataset, valid_labels))\n",
    "      print(np.argmax(predictions[0], 1), np.argmax(train_labels[offset], 1))\n",
    "  print('Test accuracy: %.1f%%' % batch_prediction(test_dataset, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, I combined the training and extra svhn datasets, then set aside the first 32,000 training records as the validation set. The testing set is  the 13,068 testing images provided as part of the SVHN dataset. The remaining 203,753 images comprise my training set.    \n",
    "I started by extracting the digiStruct data from the .mat files into numpy arrays. My bounding box and label data extraction rely heavily on the MatLab 7.3+ digistruct reader found here (https://github.com/sarahrn/Py-Gsvhn-DigitStruct-Reader).  \n",
    "I then used the bounding boxes provided to establish the outer perimeter containing all of the digits in each image by finding the minimum x and y values and the maximum x + w and y + h values.  I then expanded this encompassing bounding box by 10 pixels in every direction.  \n",
    "The image was cropped to the expanded bounding box. If the cropped image was smaller than the 64 pixel target, the bounding boxes were adjusted to match the cropping and the image was written into the output array.  If either dimension of the image exceeded 64 pixels, it and the bounding boxes were scaled down to fit.  \n",
    "My first round of testing the model on realistic data, it showed a surprising improvement over my synthetic dataset. This was a result of a bug in my conversion of the data from notMNIST to SVHN. When mapping characters to numeric representations, the notMNIST letter mapping, converted all of the SVHN numerals to the blank character. Predicting every character as blank was easy for the classifier.  \n",
    "Once I resolved the character mapping, my validation accuracy stayed below 2%, surprisingly low considering the 72% accuracy it displayed on sythetic data.  After compairing the predictions to the labels, I concluded that it was the weight regularization I had attached to the loss function drowning out the cross entropy loss from the classification. Once I removed this extra loss, validation accuracy grew to 21% in 10,000 epochs and 43% over 100,000 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ater resolving the bugs introduced by swapping datasets, the classifier achieved 43% accuracy. \n",
    "Reducing the learning rate from 0.001 to 0.0001 resulted in a 33% validation accuracy.\n",
    "\n",
    "Accuracy  Learning-Rate  Descent-Rate  Hidden  Batch  Epochs\n",
    "##%       0.001          200           128     4      100,000\n",
    "27%       0.001          200           64      16     100,000\n",
    "43%       0.001          250           64      16     100,000\n",
    "41%       0.001          250           64      16     100,000\n",
    "33%       0.0001         2500          64      16     100,000\n",
    "33%       0.001          2500          64      16     100,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the classifier dropped from 72% accuracy on the synthetic data to 43% accuracy on the realistic dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(mnist['train_labels'][0], mnist['train_bbox'][0])\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(mnist['train_dataset'][0])\n",
    "bbox = mnist['train_bbox'][0]\n",
    "rect = patches.Rectangle((bbox[0,0], bbox[0,1]), bbox[0,2], bbox[0,2], fill=None)\n",
    "ax.add_patch(rect)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tryImage = np.copy(mnist['train_dataset'][0])\n",
    "origImage = np.copy(tryImage)\n",
    "\n",
    "dst = cv2.blur(tryImage, (9,9))\n",
    "edges = cv2.Canny(tryImage, 100, 200)\n",
    "\n",
    "plt.imshow(edges), plt.xticks([]), plt.yticks([])\n",
    "print(mnist['train_labels'][0], mnist['train_dataset'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def roiGen(image, rowCount=1):\n",
    "    roiDict = {}\n",
    "    if not (rowCount > 1):\n",
    "        roiDict[(rowCount, 0, 0)] = image\n",
    "        return roiDict\n",
    "    image_shape = image.shape\n",
    "    colWidth = image_shape[0] // rowCount\n",
    "    rowHeight = image_shape[1] // rowCount\n",
    "    for i in range(rowCount):\n",
    "        i_start = i * colWidth\n",
    "        i_stop = i_start + (colWidth - 1)\n",
    "        for j in range(rowCount):\n",
    "            j_start = j * rowHeight\n",
    "            j_stop = j_start + (rowHeight -1)\n",
    "            roiDict[(rowCount, i, j)] = image[i_start:i_stop, j_start:j_stop]\n",
    "        roiDict[(rowCount, i, rowCount-1)] = image[i_start:i_stop, (rowCount-1)*rowHeight:]\n",
    "    roiDict[(rowCount, (rowCount-1), (rowCount-1))] = image[(rowCount-1)*colWidth:, (rowCount-1)*rowHeight:]\n",
    "    return roiDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(output_dim=4096, input_dim=4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Convolution2D(nb_filter=1, nb_row=2, nb_col=2, border_mode='same'))\n",
    "model.add(AveragePooling2d())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Convolution2D(nb_filter=1, nb_row=2, nb_col=2, border_mode='same'))\n",
    "model.add(AveragePooling2d())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Convolution2D(nb_filter=1, nb_row=2, nb_col=2, border_mode='same'))\n",
    "model.add(AveragePooling2d())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=55))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = mnist['train_dataset'].reshape(mnist['train_dataset'].shape[0], -1)\n",
    "Y_train = mnist['train_labels']\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_height = 64\n",
    "image_width = 64\n",
    "num_labels = 11\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = mnist['train_dataset'].reshape((-1, image_height, image_width, num_channels)).astype(np.int8)\n",
    "valid_dataset = mnist['valid_dataset'].reshape((-1, image_height, image_width, num_channels)).astype(np.int8)\n",
    "test_dataset = mnist['test_dataset'].reshape((-1, image_height, image_width, num_channels)).astype(np.int8)\n",
    "\n",
    "train_labels = mnist['train_labels']\n",
    "valid_labels = mnist['valid_labels']\n",
    "test_labels = mnist['test_labels']\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def dataBatch(data, labels, batchSize = 16):\n",
    "    limit = len(labels)\n",
    "    rChoice = []\n",
    "    for i in range(batchSize):\n",
    "        rChoice.append(random.randrange(0, limit, 1))\n",
    "    batchX = np.take(data, rChoice, axis=0)\n",
    "    batchX = batchX.reshape(batchX.shape[0], batchX.shape[1]**2)\n",
    "    batchY = np.take(labels, rChoice, axis=0)\n",
    "    return batchX, batchY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784], name=\"data\")\n",
    "y_ = tf.placeholder(tf.float32, [None, 11], name=\"true_labels\")\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 11])\n",
    "b_fc2 = bias_variable([11])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifier Function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "with sess.as_default():\n",
    "    for i in range(20000):\n",
    "      batch = dataBatch(train_dataset, train_labels, 50)\n",
    "      if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "      train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print(\"test accuracy %g\"%accuracy.eval(\n",
    "            feed_dict={x: test_dataset.reshape(\n",
    "                    test_dataset.shape[0], test_dataset.shape[1]**2), \n",
    "                       y_: test_labels, keep_prob: 1.0}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
